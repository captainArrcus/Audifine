{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Generation.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPF1CLbvN8S5mn8Ty0a2Qhj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/captainArrcus/Audifine/blob/master/Data_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMnKeNEFAUrv"
      },
      "source": [
        "'''\n",
        "  This Notebook exists to generate some own datapoints. \n",
        "  In the label_list I can put all the words, I want spoken datapoints to.\n",
        "\n",
        "  To get some more points, I mixxed the examples with different backgroundnoises. \n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWknMqf0FFyL"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6ycxnh2nNI9"
      },
      "source": [
        "!pip install pydub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA_ruto5OtUM"
      },
      "source": [
        "!apt remove libav-tools\n",
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
        "!pip install PyAudio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7N1yj6FlkWr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mppp2lZyjMd7"
      },
      "source": [
        "#Function to get soundexamples\n",
        "\n",
        "\n",
        "import pyaudio\n",
        "import wave\n",
        "def soundexample(time, filename):\n",
        "    chunk = 1024  # Record in chunks of 1024 samples\n",
        "    sample_format = pyaudio.paInt16  # 16 bits per sample\n",
        "    channels = 1\n",
        "    fs = 16000  # Record at 16000 samples per second because other soundexamples have the same\n",
        "    seconds = time\n",
        "   # filename = filename\n",
        "\n",
        "    p = pyaudio.PyAudio()  # Create an interface to PortAudio\n",
        "\n",
        "    print('Recording')\n",
        "\n",
        "    stream = p.open(format=sample_format,\n",
        "                    channels=channels,\n",
        "                    rate=fs,\n",
        "                    frames_per_buffer=chunk,\n",
        "                    input=True)\n",
        "\n",
        "    frames = []  # Initialize array to store frames\n",
        "\n",
        "    # Store data in chunks for 3 seconds\n",
        "    for i in range(0, int(fs / chunk * seconds)):\n",
        "        data = stream.read(chunk)\n",
        "        frames.append(data)\n",
        "\n",
        "    # Stop and close the stream \n",
        "    stream.stop_stream()\n",
        "    stream.close()\n",
        "    # Terminate the PortAudio interface\n",
        "    p.terminate()\n",
        "\n",
        "    print('Finished recording')\n",
        "\n",
        "    # Save the recorded data as a WAV file\n",
        "    wf = wave.open(filename, 'wb')\n",
        "    wf.setnchannels(channels)\n",
        "    wf.setsampwidth(p.get_sample_size(sample_format))\n",
        "    wf.setframerate(fs)\n",
        "    wf.writeframes(b''.join(frames))\n",
        "    wf.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vea6XaPjjRmV"
      },
      "source": [
        "#Function to split words\n",
        "\n",
        "# Import the AudioSegment class for processing audio and the \n",
        "# split_on_silence function for separating out silent chunks.\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "\n",
        "\n",
        "def split_in_single_words(input_file, input_path, output_path):\n",
        "    input_file_wav = input_path + input_file + \".wav\"\n",
        "    \n",
        "    # Load your audio.\n",
        "    song = AudioSegment.from_wav(input_file_wav)\n",
        "\n",
        "    # Split track where the silence is 2 seconds or more and get chunks using \n",
        "    # the imported function.\n",
        "    chunks = split_on_silence (\n",
        "        # Use the loaded audio.\n",
        "        song, \n",
        "        # Specify that a silent chunk must be at least 2 seconds or 2000 ms long.\n",
        "        min_silence_len = 200,\n",
        "        # Consider a chunk silent if it's quieter than -16 dBFS.\n",
        "        # (You may want to adjust this parameter.)\n",
        "        silence_thresh = -16\n",
        "    )\n",
        "    \n",
        "    \n",
        "\n",
        "    # Process each chunk with your parameters\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        \n",
        "        # Create output path\n",
        "        output = output_path + \"/\"+input_file+\"{0}.wav\"\n",
        "        \n",
        "        # Create a silence chunk that's 0.5 seconds (or 200 ms) long for padding.\n",
        "        silence_chunk = AudioSegment.silent(duration=200)\n",
        "\n",
        "        # Add the padding chunk to beginning and end of the entire chunk.\n",
        "        audio_chunk = silence_chunk + chunk + silence_chunk\n",
        "\n",
        "        # Normalize the entire chunk.\n",
        "        normalized_chunk = match_target_amplitude(audio_chunk, -20.0)\n",
        "\n",
        "        # Export the audio chunk with new bitrate.\n",
        "        \n",
        "        print(\"Exporting \"+output+\"{0}.wav.\".format(i))\n",
        "        normalized_chunk.export(\n",
        "           output.format(i),\n",
        "            bitrate = \"192k\",\n",
        "            format = \"wav\"\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PayroomjR6C"
      },
      "source": [
        "def match_target_amplitude(sound, target_dBFS):\n",
        "    change_in_dBFS = target_dBFS - sound.dBFS\n",
        "    return sound.apply_gain(change_in_dBFS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULQ3xnEMjR_k"
      },
      "source": [
        "#Mix my trainingsset up with some backgroundnoise\n",
        "\n",
        "#!!! Outputpath should NOT be file_directory or augmentation-directory, else INFINITILOOP\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import random\n",
        "\n",
        "def data_augmentation(augmentation_directory, file_directory, outputpath):\n",
        "    #Iterate over all augmentation files\n",
        "    for aug_file in os.listdir(augmentation_directory):\n",
        "        if aug_file.endswith(\".wav\"): \n",
        "            \n",
        "            # Iterate over all Trainingexamples\n",
        "            for filename in os.listdir(file_directory):\n",
        "                if filename.endswith(\".wav\"): \n",
        "                    #mix the two wav-files\n",
        "                    trainings_example = AudioSegment.from_file(file_directory + filename)\n",
        "                    augmentation = AudioSegment.from_file(augmentation_directory + aug_file)\n",
        "\n",
        "                    #randomize the backgroundnoise a little\n",
        "                    augmentation = augmentation[(random.randint(1,len(augmentation))):]\n",
        "                    augmentation = match_target_amplitude(augmentation,(random.randint(-60,-1)))\n",
        "                    #puts a random sequence from the augmented file on the sample\n",
        "                    combined = trainings_example.overlay(augmentation,gain_during_overlay = 2)\n",
        "                    #AudioSegment.overlay()\n",
        "                    #Get the of the sample right\n",
        "                    base = os.path.basename(filename)\n",
        "                    namebase = os.path.splitext(base)[0]\n",
        "                    \n",
        "                    base_aug = os.path.basename(aug_file)\n",
        "                    namebase_aug = os.path.splitext(base_aug)[0]\n",
        "                    \n",
        "                    outputfile = outputpath + namebase +'__'+ namebase_aug + '.wav'\n",
        "                    print(outputfile)\n",
        "                    combined.export(outputfile, format='wav')\n",
        "                    continue\n",
        "    #Now bring all the data together\n",
        "   # for file_name in file_directory:        \n",
        "    #    shutil.move(os.path.join(file_directory, file_name), outputpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiOXVrfJ72XI"
      },
      "source": [
        "trainings_example = AudioSegment.from_file('/content/drive/MyDrive/Audifine/Debug/Trainingsdata/Kopie von Audifine1.wav')\n",
        "augmentation = AudioSegment.from_file('/content/drive/MyDrive/Audifine/Debug/BackgroundNoise/Kopie von Home-Phone-Ringing.wav')\n",
        "#puts a random sequence from the augmented file on the sample\n",
        "augmentation =augmentation[(random.randint(1,len(augmentation))):]\n",
        "combined = trainings_example.overlay(augmentation, gain_during_overlay =2)\n",
        "print(random.randint(-60,-1))\n",
        "normalized_sound = match_target_amplitude(combined, random.randint(1,60))\n",
        "normalized_sound"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXKcmDpl3FfO"
      },
      "source": [
        "data_augmentation('/content/drive/MyDrive/Audifine/Debug/BackgroundNoise/','/content/drive/MyDrive/Audifine/Debug/Trainingsdata/','/content/drive/MyDrive/Audifine/Debug/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hasLYO_YamUE"
      },
      "source": [
        "#Correct Data Error\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "def correct_wav_files(file_directory):\n",
        "  for filename in os.listdir(file_directory):\n",
        "    if filename.endswith(\".wav\"): \n",
        "      file_path = file_directory + filename\n",
        "      bug_data,_ = librosa.load(file_path,mono=True, sr=16000, dtype = np.float32)\n",
        "\n",
        "      new_file_path = file_path + 'small'\n",
        "      sf.write(file_path,bug_data, 16000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woYPMxhof-Vq"
      },
      "source": [
        "bug_data= librosa.load('/content/drive/MyDrive/Audifine/_background_noise_/Home-Phone-Ringing.wav')\n",
        "print(bug_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rx55PUvjSCL"
      },
      "source": [
        "# Sort data, so that you can work with the tensorflow tutorial\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "def data_split_by_name(training_path,label_list):\n",
        "    file_names = os.listdir(training_path)\n",
        "    for word in label_list:\n",
        "        path = training_path + word\n",
        "        #os.makedirs(path, exist_ok=True)  // exits_ok doesn't work for me\n",
        "        if not os.path.isdir(path):\n",
        "            os.makedirs(path)\n",
        "        for file_name in file_names:\n",
        "            if file_name.startswith(word):\n",
        "                shutil.move(os.path.join(training_path, file_name), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_BF3RnbarUg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YziYohQwjSFX"
      },
      "source": [
        "import time\n",
        "#soundexample(9, \"output.wav\")\n",
        "\n",
        "\n",
        "\n",
        "#Get a List of all Words, you want to get examples from\n",
        "label_list = ['Transformer','Neural Network','CNN','Audifine','Spracherkennung','Python','Layers','Preprocessing','Tensorflow','Programmieren']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkVg33BPjSHr"
      },
      "source": [
        "path = 'train_data'\n",
        "time_to_say_an_example = 50\n",
        "for example in label_list:\n",
        "    filename = example +'.wav'\n",
        "    print('Jetzt ' + example + ' sagen')\n",
        "    time.sleep(5)\n",
        "    soundexample(time_to_say_an_example, filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_IARQKKbY3H"
      },
      "source": [
        "correct_wav_files('/content/drive/MyDrive/Audifine/')\n",
        "correct_wav_files('/content/drive/MyDrive/Audifine/_background_noise_/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UheUimTifaUp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ-d2Yi6jSQ-"
      },
      "source": [
        "#Extract single Words in my recorded Examples\n",
        "for example in label_list:\n",
        "    \n",
        "    split_in_single_words(example,'/content/drive/MyDrive/Audifine/', '/content/drive/MyDrive/Audifine/Trainingsdaten/')\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78qvhOwgjSVN"
      },
      "source": [
        "data_augmentation('/content/drive/MyDrive/Audifine/_background_noise_/','/content/drive/MyDrive/Audifine/Trainingsdaten/','/content/drive/MyDrive/Audifine/Train/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOHkxgXyjSXT"
      },
      "source": [
        "data_split_by_name('/content/drive/MyDrive/Audifine/Train/',label_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whsspfM3zAPP"
      },
      "source": [
        "#Data exploration because, theres something wrong\n",
        "import wave\n",
        "import contextlib\n",
        "from glob import glob\n",
        "\n",
        "maxframes = 0\n",
        "minframes = 10000000000 \n",
        "for i in glob(\"/content/drive/MyDrive/Audifine/Train/*\"):\n",
        "  \n",
        "  if i.endswith(\".wav\"):\n",
        "\n",
        "    fname = i \n",
        "    with contextlib.closing(wave.open(fname,'r')) as f:\n",
        "      frames = f.getnframes()\n",
        "      rate = f.getframerate()\n",
        "      duration = frames / float(rate)\n",
        "      #print(str(duration) + i)\n",
        "      if maxframes<frames:\n",
        "        maxframes=frames\n",
        "      if minframes>frames:\n",
        "        minframes=frames\n",
        "print('Die meisten Frames %s' % maxframes)\n",
        "print('Die wenigsten Frames %s' % minframes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3hw1g-91kQO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}